{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## .envファイルの作成\n",
    "\n",
    "次のセルを実行して、環境変数を格納するための`.env`ファイルを作成してください。セルの実行は、セルの左上の再生マークをクリックすることでできます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cd ..\n",
    "\n",
    "# .envファイルを作成する\n",
    "cat <<EOF > .env2\n",
    "SEARCH_SERVICE_ENDPOINT=\"your_search_service_endpoint\"\n",
    "SEARCH_QUERY_KEY=\"your_search_query_key\"\n",
    "SEARCH_API_KEY=\"your_search_api_key\"\n",
    "AOAI_ENDPOINT=\"your_aoai_endpoint\"\n",
    "AOAI_API_VERSION=2023-10-01-preview\n",
    "AOAI_API_KEY=\"your_aoai_api_key\"\n",
    "EOF\n",
    "\n",
    "echo \".envファイルが作成されました。\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 環境変数の設定\n",
    "Azure Portalで各環境変数を確認し、先ほど作成した`.env`ファイルに格納してください。\n",
    "\n",
    "1. `SEARCH_SERVICE_ENDPOINT,SEARCH_QUERY_KEY,SEARCH_API_KEY`の設定\n",
    "    - `SEARCH_SERVICE_ENDPOINT`は、AI Searchリソースの「概要」タブから確認できます。\n",
    "    ![Image 1](../assets/env1.png)\n",
    "\n",
    "    - `SEARCH_QUERY_KEY,SEARCH_API_KEY`は、AI Searchリソースの「設定」>「キー」タブから確認できます。\n",
    "    ![Image 2](../assets/env2.png)\n",
    "\n",
    "2. `AOAI_ENDPOINT,AOAI_API_KEY`の設定\n",
    "    - `AOAI_ENDPOINT,AOAI_API_KEY`は、OpenAI Servicesリソースの「リソース管理」>「キーとエンドポイント」タブから確認できます。\n",
    "    ![Image 3](../assets/env3.png)\n",
    "\n",
    "#### **※ここまで完了されたら、以降順番にセルを実行してRAGの実装を体験してみてください。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 必要なライブラリのインポート\n",
    "以下のセルで必要なライブラリをインポートします"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents.indexes.models import *\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from azure.search.documents.models import VectorizedQuery\n",
    "from PyPDF2 import PdfReader\n",
    "from openai import AzureOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 環境変数の読み込み\n",
    "envファイルから環境変数を読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 環境変数からAzure AI Search、Azure OpenAIのエンドポイント等を取得する\n",
    "load_dotenv()\n",
    "search_endpoint = os.environ[\"SEARCH_SERVICE_ENDPOINT\"]\n",
    "search_api_key = os.environ[\"SEARCH_API_KEY\"]\n",
    "search_query_key = os.environ[\"SEARCH_QUERY_KEY\"]\n",
    "aoai_endpoint = os.environ[\"AOAI_ENDPOINT\"]\n",
    "aoai_api_version = os.environ[\"AOAI_API_VERSION\"]\n",
    "aoai_api_key = os.environ[\"AOAI_API_KEY\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure AI Searchのインデックスを作成する\n",
    "\n",
    "1. **クライアントの生成**: `SearchIndexClient`を使用して、Azure AI Searchのインデックスクライアントを作成します。\n",
    "2. **インデックスの確認**: インデックスがすでに存在する場合、再作成を避けるために何もしません。\n",
    "3. **フィールドの定義**: インデックスに含まれるフィールドを定義します。ここでは、ドキュメントID、コンテンツ、コンテンツベクトルのフィールドを設定します。\n",
    "4. **ベクトル検索の設定**: ベクトル検索の設定を行います。\n",
    "5. **インデックスの作成**: 定義した設定を用いてインデックスを作成します。\n",
    "\n",
    "以下のコードを実行して、インデックスを作成します。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index():\n",
    "    \"\"\"\n",
    "    Azure AI Searchのインデックスを作成する\n",
    "    \"\"\"\n",
    "    client = SearchIndexClient(endpoint= search_endpoint, credential=AzureKeyCredential(search_api_key))\n",
    "    name = \"docs\"\n",
    "\n",
    "    # すでにインデックスが作成済みである場合には何もしない\n",
    "    if 'docs' in client.list_index_names():\n",
    "        print(\"すでにインデックスが作成済みです\")\n",
    "        return\n",
    "\n",
    "    # インデックスのフィールドを定義する\n",
    "    fields = [\n",
    "        SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True),\n",
    "        SearchableField(name=\"content\", type=\"Edm.String\", analyzer_name=\"ja.microsoft\"),\n",
    "        SearchField(name=\"contentVector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "                searchable=True, vector_search_dimensions=1536, vector_search_profile_name=\"myHnswProfile\")\n",
    "    ]\n",
    "\n",
    "    # ベクトル検索のための定義を行う\n",
    "    vector_search = VectorSearch(\n",
    "        algorithms=[\n",
    "            HnswAlgorithmConfiguration(\n",
    "                name=\"myHnsw\"\n",
    "            )\n",
    "        ],\n",
    "        profiles=[\n",
    "            VectorSearchProfile(\n",
    "                name=\"myHnswProfile\",\n",
    "                algorithm_configuration_name=\"myHnsw\",\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # インデックスを作成する\n",
    "    index = SearchIndex(name=name, fields=fields, vector_search=vector_search)\n",
    "    client.create_index(index)\n",
    "\n",
    "# インデックスを作成する\n",
    "create_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ドキュメントをAzure AI Searchにインデクシングする\n",
    "\n",
    "1. **PDFからテキストを抽出**: `PdfReader`を使用してPDFファイルからテキストを抽出します。ここでは、ドキュメントととして厚生労働省が提供する[モデル就業規則](https://www.mhlw.go.jp/content/001018385.pdf)を使用します。\n",
    "2. **テキストのチャンク化**: テキストを指定したサイズでチャンクに分割します。これにより、大きなテキストを小さな部分に分けて処理しやすくします。\n",
    "3. **インデクシング**: チャンク化されたテキストをAzure AI Searchにインデックスします。ここでは、Azure OpenAIを使用してテキストのベクトルを生成し、それを含むドキュメントをAzure AI Searchにアップロードします。\n",
    "\n",
    "以下のコードを順次実行して、ドキュメントをインデックスします。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_docs(filepath):\n",
    "    \"\"\"\n",
    "    PDFからテキストを抽出する\n",
    "    \"\"\"\n",
    "    print(f\"{filepath}内のテキストを抽出中...\")\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        reader = PdfReader(f)\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "# 対象ファイルパスのファイルを読み込んで、Azure AI Searchにインデックスする\n",
    "filepath = \"/workspaces/aoai-rag-handson/data/001018385.pdf\"  # 対象ファイルパス\n",
    "content = extract_text_from_docs(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chunk(content: str, separator: str, chunk_size: int = 512, overlap: int = 0):\n",
    "    \"\"\"\n",
    "    テキストを指定したサイズで分割する\n",
    "    \"\"\"\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_overlap=overlap, chunk_size=chunk_size, separators=separator)\n",
    "    chunks = splitter.split_text(content)\n",
    "    return chunks\n",
    "\n",
    "# テキストを指定したサイズで分割する\n",
    "chunksize = 1000  # チャンクサイズ\n",
    "overlap = 200  # オーバーラップサイズ\n",
    "separator = [\"\\n\\n\", \"\\n\", \"。\", \"、\", \" \", \"\"]  # 区切り文字\n",
    "chunks = create_chunk(content, separator, chunksize, overlap)\n",
    "print(\"チャンク化完了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_docs(chunks: list):\n",
    "    \"\"\"\n",
    "    ドキュメントをAzure AI Searchにインデックスする\n",
    "    \"\"\"\n",
    "    # Azure AI SearchのAPIに接続するためのクライアントを生成する\n",
    "    searchClient = SearchClient(\n",
    "        endpoint=search_endpoint,\n",
    "        index_name=\"docs\",\n",
    "        credential=AzureKeyCredential(search_api_key)\n",
    "    )\n",
    "\n",
    "    # Azure OpenAIのAPIに接続するためのクライアントを生成する\n",
    "    openAIClient = AzureOpenAI(\n",
    "        api_key=aoai_api_key,\n",
    "        api_version=aoai_api_version,\n",
    "        azure_endpoint=aoai_endpoint\n",
    "    )\n",
    "\n",
    "    # チャンク化されたテキストとそのテキストのベクトルをAzure AI Searchにアップロードする\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        print(f\"{i+1}個目のチャンクを処理中...\")\n",
    "        response = openAIClient.embeddings.create(\n",
    "            input=chunk,\n",
    "            model=\"text-embedding-3-small-deploy\"\n",
    "        )\n",
    "\n",
    "        # チャンク化されたテキストとそのテキストのベクトルをAzure AI Searchにアップロードする\n",
    "        document = {\"id\": str(i), \"content\": chunk, \"contentVector\": response.data[0].embedding}\n",
    "        searchClient.upload_documents([document])\n",
    "\n",
    "# テキストをAzure AI Searchにインデックスする\n",
    "index_docs(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## プロンプトのベクトル化\n",
    "\n",
    "1. **OpenAIクライアントの作成**: OpenAI APIに接続するためのクライアントを作成します。\n",
    "2. **プロンプトのベクトル化**: 指定したプロンプトをOpenAIモデルを使用してベクトル化します。このベクトルは、後の検索クエリとして使用されます。`prompt`については、任意のものに変更していただいても構いません。\n",
    "\n",
    "以下のコードを実行して、プロンプトをベクトル化します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAIクライアントの作成\n",
    "openAIClient = AzureOpenAI(\n",
    "    api_key=aoai_api_key,\n",
    "    api_version=aoai_api_version,\n",
    "    azure_endpoint=aoai_endpoint\n",
    ")\n",
    "\n",
    "# プロンプトをベクトル化する関数\n",
    "def generate_embeddings(prompt, model=\"text-embedding-3-small-deploy\"): # model = \"deployment_name\"\n",
    "    response = openAIClient.embeddings.create(input=prompt, model=model).data[0].embedding\n",
    "    return response\n",
    "\n",
    "# プロンプトをベクトル化\n",
    "prompt = \"就業時間に関してどのような規定があるのか重要度順に3つ教えてください\"\n",
    "vectorized_prompt = generate_embeddings(prompt)\n",
    "print(vectorized_prompt[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ベクトル検索\n",
    "\n",
    "1. **SearchClientの作成**: Azure AI Searchに接続するためのクライアントを作成します。\n",
    "2. **ベクトル検索の準備**: ベクトルクエリを作成し、指定されたフィールドで上位の結果を取得します。\n",
    "3. **検索実行と結果取得**: 検索を実行し、最初の検索結果を取得します。\n",
    "\n",
    "以下のコードを実行して、ベクトル検索を行います。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure AI SearchのAPIに接続するためのクライアントを生成する\n",
    "searchClient = SearchClient(\n",
    "    endpoint=search_endpoint,\n",
    "    index_name=\"docs\",\n",
    "    credential=AzureKeyCredential(search_api_key)\n",
    ")\n",
    "\n",
    "# ベクトルクエリの作成\n",
    "vector_query = VectorizedQuery(\n",
    "    vector=vectorized_prompt,\n",
    "    k_nearest_neighbors=3,  # 上位3件の結果を取得します\n",
    "    fields=\"contentVector\"  # ベクトル検索を行うフィールドを指定します\n",
    ")\n",
    "\n",
    "# ベクトル検索の実行\n",
    "results = searchClient.search(\n",
    "    search_text='',  # ベクトル検索のみ行うためテキストクエリは空\n",
    "    vector_queries=[vector_query],\n",
    "    select=['id', 'content'],\n",
    ")\n",
    "\n",
    "# 最初の検索結果を取得\n",
    "first_result = next(results, None)\n",
    "if first_result:\n",
    "    print(first_result[\"content\"])\n",
    "else:\n",
    "    print(\"検索結果が見つかりませんでした\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure OpenAIに回答生成依頼\n",
    "\n",
    "1. **システムメッセージの定義**: GPT-3.5に対するシステムメッセージを定義し、AIのキャラクターや回答スタイルを設定します。\n",
    "2. **ユーザーメッセージの作成**: 検索クエリと検索結果を含むユーザーメッセージを作成します。\n",
    "3. **回答生成の依頼**: Azure OpenAIに対して、ユーザーメッセージに基づいた回答を生成するよう依頼します。\n",
    "4. **回答の表示**: 生成された回答を表示します。\n",
    "\n",
    "以下のコードを実行して、ベクトル検索の結果に基づいた回答を生成します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure OpenAIクライアントの作成\n",
    "openAIClient = AzureOpenAI(\n",
    "    api_key=aoai_api_key,\n",
    "    api_version=aoai_api_version,\n",
    "    azure_endpoint=aoai_endpoint\n",
    ")\n",
    "\n",
    "# システムメッセージの定義\n",
    "system_message_chat_conversation = \"\"\"\n",
    "あなたはユーザーの質問に回答するチャットボットです。\n",
    "回答については、「Sources:」以下に記載されている内容に基づいて回答してください。\n",
    "回答は簡潔にしてください。\n",
    "「Sources:」に記載されている情報以外の回答はしないでください。\n",
    "また、ユーザーの質問に対して、Sources:以下に記載されている内容に基づいて適切な回答ができない場合は、「すみません。わかりません。」と回答してください。\n",
    "回答の中に情報源の提示は含めないでください。例えば、回答の中に「Sources:」という形で情報源を示すことはしないでください。\n",
    "\"\"\"\n",
    "\n",
    "# ユーザーメッセージの作成\n",
    "user_message = \"\"\"\n",
    "{query}\n",
    "\n",
    "Sources:\n",
    "{source}\n",
    "\"\"\".format(query=prompt, source=first_result[\"content\"])\n",
    "\n",
    "# メッセージリストの作成\n",
    "messages_for_vector_answer = [\n",
    "    {\"role\": \"system\", \"content\": system_message_chat_conversation},\n",
    "    {\"role\": \"user\", \"content\": user_message}\n",
    "]\n",
    "\n",
    "# Azure OpenAI Serviceに回答生成を依頼\n",
    "response = openAIClient.chat.completions.create(\n",
    "    model=\"gpt-35-turbo-deploy\",\n",
    "    messages=messages_for_vector_answer\n",
    ")\n",
    "\n",
    "# 生成された回答を表示\n",
    "response_text = response.choices[0].message.content\n",
    "print(response_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
