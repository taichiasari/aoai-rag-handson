{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 必要なライブラリのインポート\n",
    "まず、以下のセルで必要なライブラリをインポートします"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents.indexes.models import *\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from azure.search.documents.models import VectorizedQuery\n",
    "from PyPDF2 import PdfReader\n",
    "from openai import AzureOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 環境変数の読み込み\n",
    "envファイルから環境変数を読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 環境変数からAzure AI Search、Azure OpenAIのエンドポイントを取得する\n",
    "search_endpoint = os.environ[\"SEARCH_SERVICE_ENDPOINT\"]\n",
    "search_api_key = os.environ[\"SEARCH_API_KEY\"]\n",
    "search_query_key = os.environ[\"SEARCH_QUERY_KEY\"]\n",
    "aoai_endpoint = os.environ[\"AOAI_ENDPOINT\"]\n",
    "aoai_api_version = os.environ[\"AOAI_API_VERSION\"]\n",
    "aoai_api_key = os.environ[\"AOAI_API_KEY\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure AI Searchのインデックスを作成する\n",
    "\n",
    "1. **クライアントの生成**: `SearchIndexClient`を使用して、Azure AI Searchのインデックスクライアントを作成します。\n",
    "2. **インデックスの確認**: インデックスがすでに存在する場合、再作成を避けるために何もしません。\n",
    "3. **フィールドの定義**: インデックスに含まれるフィールドを定義します。ここでは、ドキュメントID、コンテンツ、コンテンツベクトルのフィールドを設定します。\n",
    "4. **ベクトル検索の設定**: ベクトル検索の設定を行います。\n",
    "5. **インデックスの作成**: 定義した設定を用いてインデックスを作成します。\n",
    "\n",
    "以下のコードを実行して、インデックスを作成します。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index():\n",
    "    \"\"\"\n",
    "    Azure AI Searchのインデックスを作成する\n",
    "    \"\"\"\n",
    "    client = SearchIndexClient(endpoint= search_endpoint, credential=AzureKeyCredential(search_api_key))\n",
    "    name = \"docs\"\n",
    "\n",
    "    # すでにインデックスが作成済みである場合には何もしない\n",
    "    if 'docs' in client.list_index_names():\n",
    "        print(\"すでにインデックスが作成済みです\")\n",
    "        return\n",
    "\n",
    "    # インデックスのフィールドを定義する\n",
    "    fields = [\n",
    "        SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True),\n",
    "        SearchableField(name=\"content\", type=\"Edm.String\", analyzer_name=\"ja.microsoft\"),\n",
    "        SearchField(name=\"contentVector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "                searchable=True, vector_search_dimensions=1536, vector_search_profile_name=\"myHnswProfile\")\n",
    "    ]\n",
    "\n",
    "    # ベクトル検索のための定義を行う\n",
    "    vector_search = VectorSearch(\n",
    "        algorithms=[\n",
    "            HnswAlgorithmConfiguration(\n",
    "                name=\"myHnsw\"\n",
    "            )\n",
    "        ],\n",
    "        profiles=[\n",
    "            VectorSearchProfile(\n",
    "                name=\"myHnswProfile\",\n",
    "                algorithm_configuration_name=\"myHnsw\",\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # インデックスを作成する\n",
    "    index = SearchIndex(name=name, fields=fields, vector_search=vector_search)\n",
    "    client.create_index(index)\n",
    "\n",
    "# インデックスを作成する\n",
    "create_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ドキュメントをAzure AI Searchにインデクシングする\n",
    "\n",
    "1. **PDFからテキストを抽出**: `PdfReader`を使用してPDFファイルからテキストを抽出します。\n",
    "2. **テキストのチャンク化**: テキストを指定したサイズでチャンクに分割します。これにより、大きなテキストを小さな部分に分けて処理しやすくします。\n",
    "3. **インデクシング**: チャンク化されたテキストをAzure AI Searchにインデックスします。ここでは、Azure OpenAIを使用してテキストのベクトルを生成し、それを含むドキュメントをAzure AI Searchにアップロードします。\n",
    "\n",
    "以下のコードを順次実行して、ドキュメントをインデックスします。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/aoai-rag-handson/data/001018385.pdf内のテキストを抽出中...\n"
     ]
    }
   ],
   "source": [
    "def extract_text_from_docs(filepath):\n",
    "    \"\"\"\n",
    "    PDFからテキストを抽出する\n",
    "    \"\"\"\n",
    "    print(f\"{filepath}内のテキストを抽出中...\")\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        reader = PdfReader(f)\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "# 対象ファイルパスのファイルを読み込んで、Azure AI Searchにインデックスする\n",
    "filepath = \"/workspaces/aoai-rag-handson/data/001018385.pdf\"  # 対象ファイルパス\n",
    "content = extract_text_from_docs(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chunk(content: str, separator: str, chunk_size: int = 512, overlap: int = 0):\n",
    "    \"\"\"\n",
    "    テキストを指定したサイズで分割する\n",
    "    \"\"\"\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_overlap=overlap, chunk_size=chunk_size, separators=separator)\n",
    "    chunks = splitter.split_text(content)\n",
    "    return chunks\n",
    "\n",
    "# テキストを指定したサイズで分割する\n",
    "chunksize = 1000  # チャンクサイズ\n",
    "overlap = 200  # オーバーラップサイズ\n",
    "separator = [\"\\n\\n\", \"\\n\", \"。\", \"、\", \" \", \"\"]  # 区切り文字\n",
    "chunks = create_chunk(content, separator, chunksize, overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1個目のチャンクを処理中...\n",
      "2個目のチャンクを処理中...\n",
      "3個目のチャンクを処理中...\n",
      "4個目のチャンクを処理中...\n",
      "5個目のチャンクを処理中...\n",
      "6個目のチャンクを処理中...\n",
      "7個目のチャンクを処理中...\n",
      "8個目のチャンクを処理中...\n",
      "9個目のチャンクを処理中...\n",
      "10個目のチャンクを処理中...\n",
      "11個目のチャンクを処理中...\n",
      "12個目のチャンクを処理中...\n",
      "13個目のチャンクを処理中...\n",
      "14個目のチャンクを処理中...\n",
      "15個目のチャンクを処理中...\n",
      "16個目のチャンクを処理中...\n",
      "17個目のチャンクを処理中...\n",
      "18個目のチャンクを処理中...\n",
      "19個目のチャンクを処理中...\n",
      "20個目のチャンクを処理中...\n",
      "21個目のチャンクを処理中...\n",
      "22個目のチャンクを処理中...\n",
      "23個目のチャンクを処理中...\n",
      "24個目のチャンクを処理中...\n",
      "25個目のチャンクを処理中...\n",
      "26個目のチャンクを処理中...\n",
      "27個目のチャンクを処理中...\n",
      "28個目のチャンクを処理中...\n",
      "29個目のチャンクを処理中...\n",
      "30個目のチャンクを処理中...\n",
      "31個目のチャンクを処理中...\n",
      "32個目のチャンクを処理中...\n",
      "33個目のチャンクを処理中...\n",
      "34個目のチャンクを処理中...\n",
      "35個目のチャンクを処理中...\n",
      "36個目のチャンクを処理中...\n",
      "37個目のチャンクを処理中...\n",
      "38個目のチャンクを処理中...\n",
      "39個目のチャンクを処理中...\n",
      "40個目のチャンクを処理中...\n",
      "41個目のチャンクを処理中...\n",
      "42個目のチャンクを処理中...\n",
      "43個目のチャンクを処理中...\n",
      "44個目のチャンクを処理中...\n",
      "45個目のチャンクを処理中...\n",
      "46個目のチャンクを処理中...\n",
      "47個目のチャンクを処理中...\n",
      "48個目のチャンクを処理中...\n",
      "49個目のチャンクを処理中...\n",
      "50個目のチャンクを処理中...\n",
      "51個目のチャンクを処理中...\n",
      "52個目のチャンクを処理中...\n",
      "53個目のチャンクを処理中...\n",
      "54個目のチャンクを処理中...\n",
      "55個目のチャンクを処理中...\n",
      "56個目のチャンクを処理中...\n",
      "57個目のチャンクを処理中...\n",
      "58個目のチャンクを処理中...\n",
      "59個目のチャンクを処理中...\n",
      "60個目のチャンクを処理中...\n",
      "61個目のチャンクを処理中...\n",
      "62個目のチャンクを処理中...\n",
      "63個目のチャンクを処理中...\n",
      "64個目のチャンクを処理中...\n",
      "65個目のチャンクを処理中...\n",
      "66個目のチャンクを処理中...\n",
      "67個目のチャンクを処理中...\n",
      "68個目のチャンクを処理中...\n",
      "69個目のチャンクを処理中...\n",
      "70個目のチャンクを処理中...\n",
      "71個目のチャンクを処理中...\n",
      "72個目のチャンクを処理中...\n",
      "73個目のチャンクを処理中...\n",
      "74個目のチャンクを処理中...\n",
      "75個目のチャンクを処理中...\n",
      "76個目のチャンクを処理中...\n",
      "77個目のチャンクを処理中...\n",
      "78個目のチャンクを処理中...\n",
      "79個目のチャンクを処理中...\n",
      "80個目のチャンクを処理中...\n",
      "81個目のチャンクを処理中...\n",
      "82個目のチャンクを処理中...\n",
      "83個目のチャンクを処理中...\n",
      "84個目のチャンクを処理中...\n",
      "85個目のチャンクを処理中...\n",
      "86個目のチャンクを処理中...\n",
      "87個目のチャンクを処理中...\n",
      "88個目のチャンクを処理中...\n",
      "89個目のチャンクを処理中...\n",
      "90個目のチャンクを処理中...\n",
      "91個目のチャンクを処理中...\n",
      "92個目のチャンクを処理中...\n",
      "93個目のチャンクを処理中...\n",
      "94個目のチャンクを処理中...\n",
      "95個目のチャンクを処理中...\n",
      "96個目のチャンクを処理中...\n",
      "97個目のチャンクを処理中...\n",
      "98個目のチャンクを処理中...\n",
      "99個目のチャンクを処理中...\n"
     ]
    }
   ],
   "source": [
    "def index_docs(chunks: list):\n",
    "    \"\"\"\n",
    "    ドキュメントをAzure AI Searchにインデックスする\n",
    "    \"\"\"\n",
    "    # Azure AI SearchのAPIに接続するためのクライアントを生成する\n",
    "    searchClient = SearchClient(\n",
    "        endpoint=search_endpoint,\n",
    "        index_name=\"docs\",\n",
    "        credential=AzureKeyCredential(search_api_key)\n",
    "    )\n",
    "\n",
    "    # Azure OpenAIのAPIに接続するためのクライアントを生成する\n",
    "    openAIClient = AzureOpenAI(\n",
    "        api_key=aoai_api_key,\n",
    "        api_version=aoai_api_version,\n",
    "        azure_endpoint=aoai_endpoint\n",
    "    )\n",
    "\n",
    "    # チャンク化されたテキストとそのテキストのベクトルをAzure AI Searchにアップロードする\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        print(f\"{i+1}個目のチャンクを処理中...\")\n",
    "        response = openAIClient.embeddings.create(\n",
    "            input=chunk,\n",
    "            model=\"text-embedding-3-small-deploy\"\n",
    "        )\n",
    "\n",
    "        # チャンク化されたテキストとそのテキストのベクトルをAzure AI Searchにアップロードする\n",
    "        document = {\"id\": str(i), \"content\": chunk, \"contentVector\": response.data[0].embedding}\n",
    "        searchClient.upload_documents([document])\n",
    "\n",
    "# テキストをAzure AI Searchにインデックスする\n",
    "index_docs(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## プロンプトのベクトル化\n",
    "\n",
    "1. **OpenAIクライアントの作成**: OpenAI APIに接続するためのクライアントを作成します。\n",
    "2. **プロンプトのベクトル化**: 指定したプロンプトをOpenAIモデルを使用してベクトル化します。このベクトルは、後の検索クエリとして使用されます。\n",
    "\n",
    "以下のコードを実行して、プロンプトをベクトル化します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.007567174732685089, 0.01277646142989397, 0.07194299250841141, -0.009398650377988815, 0.03917383775115013, 0.012919032014906406, 0.012765495106577873, -0.005538294557482004, 0.021451294422149658, -0.01731676608324051, 0.0035368315875530243, 0.050316229462623596, -0.009097060188651085, 0.009820876643061638, -0.010478892363607883, -0.03226467967033386, -0.019872058182954788, -0.03000549226999283, 0.021506130695343018, 0.04116981849074364, 0.011953942477703094, 0.024368496611714363, -0.024851040914654732, 0.03366844356060028, 0.005922136828303337, -0.013522212393581867, 0.035159945487976074, -0.002153628971427679, 0.024280760437250137, -0.05062330141663551, -0.0041701714508235455, -0.04320966452360153, -0.005724732298403978, -0.008680317550897598, -0.005409433040767908, 0.03362457826733589, 0.014662771485745907, 0.026627682149410248, -0.00857613142579794, -0.0404021330177784, -0.014070558361709118, -0.020617809146642685, 0.040116991847753525, -0.07957597076892853, -0.043275464326143265, 0.044635362923145294, -0.05106198042631149, 0.06110767647624016, 0.012392619624733925, 0.04375800862908363]\n"
     ]
    }
   ],
   "source": [
    "# OpenAIクライアントの作成\n",
    "openAIClient = AzureOpenAI(\n",
    "    api_key=aoai_api_key,\n",
    "    api_version=aoai_api_version,\n",
    "    azure_endpoint=aoai_endpoint\n",
    ")\n",
    "\n",
    "# プロンプトをベクトル化する関数\n",
    "def generate_embeddings(prompt, model=\"text-embedding-3-small-deploy\"): # model = \"deployment_name\"\n",
    "    response = openAIClient.embeddings.create(input=prompt, model=model).data[0].embedding\n",
    "    return response\n",
    "\n",
    "# プロンプトをベクトル化\n",
    "prompt = \"就業時間に関してどのような規定があるのか重要度順に3つ教えてください\"\n",
    "vectorized_prompt = generate_embeddings(prompt)\n",
    "print(vectorized_prompt[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ベクトル検索\n",
    "\n",
    "1. **SearchClientの作成**: Azure AI Searchに接続するためのクライアントを作成します。\n",
    "2. **ベクトル検索の準備**: ベクトルクエリを作成し、指定されたフィールドで上位の結果を取得します。\n",
    "3. **検索実行と結果取得**: 検索を実行し、最初の検索結果を取得します。\n",
    "\n",
    "以下のコードを実行して、ベクトル検索を行います。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "す。）は、１週４４時間まで働かせることが認められています（労基法第４０条、労基則\n",
      "第２５条の２）。 \n",
      "また、労基法第３２条第２項において、１日の労働時間の上限は８時間と定められて\n",
      "います。 \n",
      "３ 休憩時間については、１日の労働時間が６時間を超える場合には少なくとも４５分、\n",
      "８時間を超える場合には少なくとも１時間の休憩時間を与えなければなりません（労基\n",
      "法第３４条）。 \n",
      "４ 休日については、毎週少なくとも１回又は４週間を通じ４日以上与えなければなりま\n",
      "せん（労基法第３５条）。 \n",
      "５ 上記２から４までの労基法の規定に適合する労働条件とするためには、①週休２日制\n",
      "とする、②週休１日制で１日の所定労働時間を短く設定する、③変形労働時間制（１か\n",
      "月単位、１年単位等）を導入する等の方法がありますので、それぞれの事業場の実情に\n",
      "応じて、下記の規程例を参考に就業規則を作成してください。 \n",
      " \n",
      " \n",
      " \n",
      "［例１］ 完全週休２日制を採用する場合の規程例 \n",
      " \n",
      "１日の労働時間を８時間とし、完全週休２日制を採用する場合の規程例です。 \n",
      " \n",
      "(労働時間及び休憩時間)  \n",
      "第１９条  労働時間は、１週間については４０時間、１日については８時間とする。 \n",
      "２ 始業・終業の時刻及び休憩時間は、次のとおりとする。ただし、業務の都合その他\n",
      "やむを得ない事情により、これらを繰り上げ、又は繰り下げることがある。この場合、   \n",
      "前日までに労働者に通知する。 \n",
      " \n",
      " - 23 - \n",
      " ① 一般勤務 \n",
      "始業・終業時刻 休憩時間 \n",
      "始業  午前  時  分 \n",
      "  時  分から  時  分まで \n",
      "終業  午後  時  分 \n",
      " \n",
      "② 交替勤務 \n",
      " （イ）１番（日勤） \n",
      "始業・終業時刻 休憩時間 \n",
      "始業  午前  時  分 \n",
      "  時  分から  時  分まで \n",
      "終業  午後  時  分 \n",
      " \n",
      "（ロ）２番（準夜勤） \n",
      "始業・終業時刻 休憩時間 \n",
      "始業  午前  時  分 \n",
      "  時  分から  時  分まで \n",
      "終業  午後  時  分 \n",
      " \n",
      "（ハ）３番（夜勤） \n",
      "始業・終業時刻 休憩時間 \n",
      "始業  午前  時  分 \n",
      "  時  分から  時  分まで \n",
      "終業  午後  時  分 \n",
      " \n",
      "３ 交替勤務における各労働者の勤務は、別に定めるシフト表により、前月の   日\n",
      "までに各労働者に通知する。\n"
     ]
    }
   ],
   "source": [
    "# Azure AI SearchのAPIに接続するためのクライアントを生成する\n",
    "searchClient = SearchClient(\n",
    "    endpoint=search_endpoint,\n",
    "    index_name=\"docs\",\n",
    "    credential=AzureKeyCredential(search_api_key)\n",
    ")\n",
    "\n",
    "# ベクトルクエリの作成\n",
    "vector_query = VectorizedQuery(\n",
    "    vector=vectorized_prompt,\n",
    "    k_nearest_neighbors=3,  # 上位3件の結果を取得します\n",
    "    fields=\"contentVector\"  # ベクトル検索を行うフィールドを指定します\n",
    ")\n",
    "\n",
    "# ベクトル検索の実行\n",
    "results = searchClient.search(\n",
    "    search_text='',  # ベクトル検索のみ行うためテキストクエリは空\n",
    "    vector_queries=[vector_query],\n",
    "    select=['id', 'content'],\n",
    ")\n",
    "\n",
    "# 最初の検索結果を取得\n",
    "first_result = next(results, None)\n",
    "if first_result:\n",
    "    print(first_result[\"content\"])\n",
    "else:\n",
    "    print(\"検索結果が見つかりませんでした\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure OpenAIに回答生成依頼\n",
    "\n",
    "1. **システムメッセージの定義**: GPT-3.5に対するシステムメッセージを定義し、AIのキャラクターや回答スタイルを設定します。\n",
    "2. **ユーザーメッセージの作成**: 検索クエリと検索結果を含むユーザーメッセージを作成します。\n",
    "3. **回答生成の依頼**: Azure OpenAIに対して、ユーザーメッセージに基づいた回答を生成するよう依頼します。\n",
    "4. **回答の表示**: 生成された回答を表示します。\n",
    "\n",
    "以下のコードを実行して、ベクトル検索の結果に基づいた回答を生成します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 労働時間の上限は1日8時間、週44時間までです。 \n",
      "2. 労働時間が6時間を超える場合には、少なくとも45分、8時間を超える場合には少なくとも1時間の休憩時間を与える必要があります。 \n",
      "3. 休日については、毎週少なくとも1回又は4週間を通じ4日以上与えなければなりません。\n"
     ]
    }
   ],
   "source": [
    "# Azure OpenAIクライアントの作成\n",
    "openAIClient = AzureOpenAI(\n",
    "    api_key=aoai_api_key,\n",
    "    api_version=aoai_api_version,\n",
    "    azure_endpoint=aoai_endpoint\n",
    ")\n",
    "\n",
    "# システムメッセージの定義\n",
    "system_message_chat_conversation = \"\"\"\n",
    "あなたはユーザーの質問に回答するチャットボットです。\n",
    "回答については、「Sources:」以下に記載されている内容に基づいて回答してください。\n",
    "回答は簡潔にしてください。\n",
    "「Sources:」に記載されている情報以外の回答はしないでください。\n",
    "また、ユーザーの質問に対して、Sources:以下に記載されている内容に基づいて適切な回答ができない場合は、「すみません。わかりません。」と回答してください。\n",
    "回答の中に情報源の提示は含めないでください。例えば、回答の中に「Sources:」という形で情報源を示すことはしないでください。\n",
    "\"\"\"\n",
    "\n",
    "# ユーザーメッセージの作成\n",
    "user_message = \"\"\"\n",
    "{query}\n",
    "\n",
    "Sources:\n",
    "{source}\n",
    "\"\"\".format(query=prompt, source=first_result[\"content\"])\n",
    "\n",
    "# メッセージリストの作成\n",
    "messages_for_vector_answer = [\n",
    "    {\"role\": \"system\", \"content\": system_message_chat_conversation},\n",
    "    {\"role\": \"user\", \"content\": user_message}\n",
    "]\n",
    "\n",
    "# Azure OpenAI Serviceに回答生成を依頼\n",
    "response = openAIClient.chat.completions.create(\n",
    "    model=\"gpt-35-turbo-deploy\",\n",
    "    messages=messages_for_vector_answer\n",
    ")\n",
    "\n",
    "# 生成された回答を表示\n",
    "response_text = response.choices[0].message.content\n",
    "print(response_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
